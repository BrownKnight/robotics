{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_steering_model_xy.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model = model.eval().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481d4b50f2f5417cb5017a2971f9802b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "#using realsense to capture the color and depth image\n",
    "import pyrealsense2 as rs\n",
    "#multi-threading is used to capture the image in real time performance\n",
    "import threading\n",
    "\n",
    "class Camera(SingletonConfigurable):\n",
    "    \n",
    "    #this changing of these two values will be captured by traitlets\n",
    "    color_value = traitlets.Any()\n",
    "    depth_value = traitlets.Any()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "        #self.i=0\n",
    "        #configure the color and depth sensor\n",
    "        \n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.configuration = rs.config()  \n",
    "        fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
    "        self.out = cv2.VideoWriter('output.mp4',fourcc, 30.0, (640,480))\n",
    "        #set resolution for the color camera\n",
    "        self.color_width = 640\n",
    "        self.color_height = 480\n",
    "        self.color_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.color, self.color_width, self.color_height, rs.format.bgr8, self.color_fps)\n",
    "\n",
    "        #set resolution for the depth camera\n",
    "        self.depth_width = 640\n",
    "        self.depth_height = 480\n",
    "        self.depth_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.depth, self.depth_width, self.depth_height, rs.format.z16, self.depth_fps)\n",
    "\n",
    "        self.stop_flag = False\n",
    "        \n",
    "        #start capture the first depth and color image\n",
    "        self.pipeline.start(self.configuration)\n",
    "        self.pipeline_started = True\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "\n",
    "        color_frame = frames.get_color_frame()   \n",
    "        image = np.asanyarray(color_frame.get_data())\n",
    "        self.color_value = image\n",
    "\n",
    "        depth_frame = frames.get_depth_frame()           \n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        self.depth_value = depth_colormap    \n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while(self.stop_flag==False):\n",
    "            frames = self.pipeline.wait_for_frames()\n",
    "            color_frame = frames.get_color_frame()\n",
    "            image = np.asanyarray(color_frame.get_data())\n",
    "            self.color_value = image\n",
    "\n",
    "            depth_frame = frames.get_depth_frame()              \n",
    "            depth_image = np.asanyarray(depth_frame.get_data())\n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            self.depth_value = depth_colormap\n",
    "            #cv2.imwrite(str(self.i)+'.jpg',image)\n",
    "            #self.i+=1\n",
    "            self.out.write(self.color_value)\n",
    "    def start(self):\n",
    "        if not hasattr(self, 'thread') or not self.thread.isAlive():\n",
    "            self.thread = threading.Thread(target=self._capture_frames)\n",
    "            self.thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "        if hasattr(self, 'thread'):\n",
    "            self.thread.join()        \n",
    "        if self.pipeline_started:\n",
    "            self.pipeline.stop()\n",
    "        self.out.release()\n",
    "def bgr8_to_jpeg(value,quality=75):\n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "#create a camera object\n",
    "camera = Camera.instance()\n",
    "\n",
    "image_widget = ipywidgets.Image()\n",
    "\n",
    "traitlets.dlink((camera, 'color_value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RobotClass import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9a3fe2d2e64c2bbb87a1114e7df2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a37d8f701f4b2baf16e86b0a69fa17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.2, description='steering gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acc815227c1442c89dbad316291816a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering kd', max=0.5, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78c32c27d3d4a76b8107a8ed5353c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering bias', max=0.3, min=-0.3, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.2, description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d67d528475e42e284b6552c1e34ccb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='y', max=1.0, orientation='vertical'), FloatSlider(value=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d39e5da3e544a385f4906c67b57cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.9427734375000001, description='x', max=10.0, min=-10.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49027e2f061d4767859611ffabd0b8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.08897068108303745, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_slider = ipywidgets.FloatSlider(min=-10.0, max=10.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "display(ipywidgets.HBox([y_slider, speed_slider]))\n",
    "display(x_slider, steering_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "def normalisex(x):\n",
    "    x = 2*((x+4)/(5)) - 1\n",
    "    return x\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last\n",
    "    image = change['new']\n",
    "    xy = model(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "    x= xy[0]\n",
    "    y = xy[1]\n",
    "    \n",
    "    x_slider.value = x\n",
    "    y_slider.value = y\n",
    "    \n",
    "    speed_slider.value = speed_gain_slider.value\n",
    "    \n",
    "    angle = np.arctan2(x, y)\n",
    "    pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid + steering_bias_slider.value\n",
    "    robot.set_motors(max(min(speed_slider.value + steering_slider.value, 1.0), 0.0), \n",
    "                     max(min(speed_slider.value - steering_slider.value, 1.0), 0.0), \n",
    "                     max(min(speed_slider.value + steering_slider.value, 1.0), 0.0), \n",
    "                     max(min(speed_slider.value - steering_slider.value, 1.0), 0.0))\n",
    "    \n",
    "execute({'new': camera.color_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start() # start capturing the data\n",
    "camera.observe(execute, names='color_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "camera.stop()\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
